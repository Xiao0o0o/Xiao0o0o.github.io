<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Tutorial: Uncertainty Quantification and Confidence Calibration in LLMs</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="hero">
    <div class="hero-text">
      <h1>Uncertainty Quantification and Confidence Calibration in Large<br>Language Models</h1>
      <p>2025 KDD Lecture-style Tutorial</p>
      <p>Sunday, August 3 &nbsp; 8:00 AM â€“ 11:00 AM</p>
      <p>Location: TBD</p>
    </div>
  </div>

  <section class="abstract">
    <h2>Abstract</h2>
    <p>
      Large Language Models (LLMs) excel in text generation, reasoning, and decision-making, enabling their adoption in high-stakes domains such as healthcare, law, and transportation. However, their reliability is a major concern, as they often produce plausible but incorrect responses. Uncertainty quantification (UQ) enhances trustworthiness by estimating confidence in outputs, enabling risk mitigation and selective prediction.
    </p>
    <p>
      However, traditional UQ methods struggle with LLMs due to computational constraints and decoding inconsistencies. Moreover, LLMs introduce unique uncertainty sources, such as input ambiguity, reasoning path divergence, and decoding stochasticity, that extend beyond classical aleatoric and epistemic uncertainty. To address this, we introduce a new taxonomy that categorizes UQ methods based on computational efficiency and uncertainty dimensions (input, reasoning, parameter, and prediction uncertainty). We evaluate existing techniques, assess their real-world applicability, and identify open challenges, emphasizing the need for scalable, interpretable, and robust UQ approaches to enhance LLM reliability.
    </p>
  </section>

  <section class="schedule">
    <h2>Schedule</h2>
    <ul>
      <li><strong>Section 1: Introduction and Overview (10 min)</strong><br>
        - The rise of LLMs<br>
        - Importance of reliability in LLMs, especially in high-stakes domains<br>
        - Need for Uncertainty Quantification and Confidence Calibration
      </li>
      <li><strong>Section 2: Define and understand LLM Uncertainty and Confidence</strong><br>
        - Traditional UQ<br>
        - Aleatoric & Epistemic Uncertainty<br>
        - From traditional to LLM: insufficiency of categories alone<br>
        - Uncertainty vs. Confidence
      </li>
      <li><strong>Section 3: UQ Methods (90 min)</strong><br>
        - Input uncertainty methods<br>
        - Reasoning uncertainty methods<br>
        - Parameter uncertainty methods<br>
        - Prediction uncertainty methods<br>
        <em>(Break - 10 min)</em>
      </li>
      <li><strong>Section 4: Confidence (20 min)</strong><br>
        - Confidence Estimation and Calibration<br>
        - LLM Calibration methods
      </li>
      <li><strong>Section 5: Applications (15 min)</strong><br>
        - Robotics<br>
        - Transportation<br>
        - Healthcare<br>
        - Education
      </li>
      <li><strong>Section 6: Open Challenges and Future Directions (20 min)</strong><br>
        - Efficiency-Performance Trade-offs<br>
        - Interpretability Deficits<br>
        - Cross-Modality Uncertainty<br>
        - Interventions for Uncertainty<br>
        - UQ Evaluation
      </li>
      <li><strong>Q&A</strong></li>
    </ul>
  </section>

  <section class="materials">
    <h2>Materials</h2>
    <ul>
      <li><a href="slides.pdf" download>Download Slides (PDF)</a></li>
      <li><a href="survey.pdf" download>Download Survey Paper (PDF)</a></li>
    </ul>
  </section>

  <section class="speakers">
    <h2>Speakers</h2>
    <div class="speaker-grid">
      <div class="speaker">
        <img src="people/xiaoou.png" alt="Xiaoou Liu">
        <p><strong>Xiaoou Liu</strong><br>Affiliation and short bio.</p>
      </div>
      <div class="speaker">
        <img src="people/tiejin.png" alt="Tiejin Chen">
        <p><strong>Tiejin Chen</strong><br>Affiliation and short bio.</p>
      </div>
      <div class="speaker">
        <img src="people/longchao.png" alt="Longchao Da">
        <p><strong>Longchao Da</strong><br>Affiliation and short bio.</p>
      </div>
      <div class="speaker">
        <img src="people/chacha.jpg" alt="Chacha Chen">
        <p><strong>Chacha Chen</strong><br>Affiliation and short bio.</p>
      </div>
      <div class="speaker">
        <img src="people/hua.png" alt="Hua Wei">
        <p><strong>Hua Wei</strong><br>Affiliation and short bio.</p>
      </div>
      <!-- <div class="speaker">
        <img src="people/" alt="Speaker 6">
        <p><strong>Name 6</strong><br>Affiliation and short bio.</p>
      </div> -->
    </div>
  </section>
</body>
</html>
