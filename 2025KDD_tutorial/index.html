<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Tutorial: Uncertainty Quantification and Confidence Calibration in LLMs</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header class="header">
    <div class="logo-container">
      <a href="https://kdd2025.kdd.org/call-for-lecture-style-tutorials/" target="_blank">
        <img src="KDD25-Logo3.png" alt="KDD 2025 Logo" class="logo">
      </a>
    </div>
    <nav class="navbar">
      <ul>
        <li><a href="#home">Home</a></li>
        <li><a href="#schedule">Schedule</a></li>
        <li><a href="#materials">Tutorial Materials</a></li>
        <li><a href="#contributors">Contributors</a></li>
      </ul>
    </nav>
  </header>

  <div class="hero" id="home">
  <!-- <div class="hero"> -->
    <div class="hero-text">
      <h1>Uncertainty Quantification and Confidence Calibration <br> in Large Language Models</h1>
      <p>2025 KDD Lecture-style Tutorial</p>
      <p>Sunday, August 3 &nbsp; 8:00 AM â€“ 11:00 AM</p>
      <p>Location: MTCC</p>
    </div>
  </div>

  <section class="abstract">
    <h2>Abstract</h2>
    <p>
      Large Language Models (LLMs) excel in text generation, reasoning, and decision-making, enabling their adoption in high-stakes domains such as healthcare, law, and transportation. However, their reliability is a major concern, as they often produce plausible but incorrect responses. Uncertainty quantification (UQ) enhances trustworthiness by estimating confidence in outputs, enabling risk mitigation and selective prediction.
    </p>
    <p>
      However, traditional UQ methods struggle with LLMs due to computational constraints and decoding inconsistencies. Moreover, LLMs introduce unique uncertainty sources, such as input ambiguity, reasoning path divergence, and decoding stochasticity, that extend beyond classical aleatoric and epistemic uncertainty. To address this, we introduce a new taxonomy that categorizes UQ methods based on computational efficiency and uncertainty dimensions (input, reasoning, parameter, and prediction uncertainty). We evaluate existing techniques, assess their real-world applicability, and identify open challenges, emphasizing the need for scalable, interpretable, and robust UQ approaches to enhance LLM reliability.
    </p>
  </section>

  <section class="schedule", id="schedule">
    <h2>Schedule</h2>
    <ul>
      <li><strong>Section 1: Introduction and Overview (10 min)</strong><br>
        - LLMs and their growth<br>
        - Reliability concerns in sensitive applications<br>
        - Why we need Uncertainty Quantification and Confidence Calibration
      </li>
      <li><strong>Section 2: Define and understand LLM Uncertainty and Confidence (15 min)</strong><br>
        - Traditional UQ methods<br>
        - Aleatoric & Epistemic Uncertainty<br>
        - Limitations of traditional categories for LLMs<br>
        - Uncertainty vs. Confidence
      </li>
      <li><strong>Section 3: UQ Methodsc in LLMs (90 min)</strong><br>
        - Input uncertainty methods<br>
        - Reasoning uncertainty methods<br>
        - Parameter uncertainty methods<br>
        - Prediction uncertainty methods<br>
        <br><em>(Break - 10 min)</em><br>
      </li>
      <li><strong>Section 4: Confidence (20 min)</strong><br>
        - Confidence Estimation and Calibration<br>
        - Calibration methods in LLMs<br>
      </li>
      <li><strong>Section 5: Applications (15 min)</strong><br>
        - Robotics<br>
        - Transportation<br>
        - Healthcare<br>
        - Education
      </li>
      <li><strong>Section 6: Open Challenges and Future Directions (20 min)</strong><br>
        - Efficiency-Performance Trade-offs<br>
        - Interpretability Deficits<br>
        - Cross-Modality Uncertainty<br>
        - Interventions for Uncertainty<br>
        - UQ Evaluation
      </li>
      <li><strong>Q&A</strong></li>
    </ul>
  </section>

  <section class="materials", id="materials">
    <h2>Tutorial Materials</h2>
    <ul>
      <li><a href="slides.pdf" download>Download Slides (TBD)</a></li>
      <li><a href="survey.pdf" download>Download Survey Paper (PDF)</a></li>
    </ul>
  </section>

  <section class="speakers",id="contributors">
    <h2>Contributors</h2>
    <div class="speaker-grid">
      <div class="speaker">
        <img src="people/xiaoou.png" alt="Xiaoou Liu">
        <p><strong>Xiaoou Liu</strong><br>Affiliation and short bio.</p>
      </div>
      <div class="speaker">
        <img src="people/tiejin.png" alt="Tiejin Chen">
        <p><strong>Tiejin Chen</strong><br>Affiliation and short bio.</p>
      </div>
      <div class="speaker">
        <img src="people/longchao.png" alt="Longchao Da">
        <p><strong>Longchao Da</strong><br>Affiliation and short bio.</p>
      </div>
      <div class="speaker">
        <img src="people/" alt="Speaker 6">
        <p><strong>Zhen Lin</strong><br>Affiliation and short bio.</p>
      </div>
      <div class="speaker">
        <img src="people/chacha.jpg" alt="Chacha Chen">
        <p><strong>Chacha Chen</strong><br>Affiliation and short bio.</p>
      </div>
      <div class="speaker">
        <img src="people/hua.png" alt="Hua Wei">
        <p><strong>Hua Wei</strong><br>Affiliation and short bio.</p>
      </div>
    </div>
  </section>
</body>
</html>
