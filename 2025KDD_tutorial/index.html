<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Tutorial: Uncertainty Quantification and Confidence Calibration in LLMs</title>
  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <style>
  
    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }
    
    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
      line-height: 1.6;
      color: #333;
      background-color: #f9f9f9;
    }
    
    
    .header {
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      display: flex;
      justify-content: space-between;
      align-items: center;
      background-color: #ffffff;
      padding: 10px 30px;
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
      z-index: 1000;
    }
    
    .logo img {
      height: 45px;
      width: auto;
    }
    
    /* Navigation */
    .navbar {
      display: flex;
      background-color: #2c3e50;
      border-radius: 8px;
      overflow: hidden;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
    }
    
    .navbar a {
      text-decoration: none;
      color: #ffffff;
      padding: 12px 24px;
      font-weight: 500;
      font-size: 15px;
      transition: all 0.3s ease;
      position: relative;
    }
    
    .navbar a:not(:last-child)::after {
      content: '';
      position: absolute;
      right: 0;
      top: 50%;
      transform: translateY(-50%);
      height: 20px;
      width: 1px;
      background-color: rgba(255, 255, 255, 0.2);
    }
    
    .navbar a:hover {
      background-color: #34495e;
      color: #fff;
    }
    
    .navbar a:active {
      background-color: #1a252f;
    }
    
    /* Hero section */
    .hero {
      margin-top: 70px; 
      background-image: url('background3.jpg');
      background-size: cover;
      background-position: center;
      padding: 100px 20px;
      color: white;
      text-align: center;
      position: relative;
    }
    
    
    .hero::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background-color: rgba(0, 0, 0, 0.4);
      z-index: 1;
    }
    
    .hero-content {
      position: relative;
      z-index: 2;
    }
    
    .hero h1 {
      font-size: 2.5em;
      font-weight: 700;
      margin-bottom: 20px;
      line-height: 1.2;
      color: #ffffff;
    }
    
    .hero p {
      font-size: 1.2em;
      font-weight: 300;
      margin-bottom: 10px;
      color: #ffffff;
    }
    
    .hero a {
      color: #ffffff;
      text-decoration: underline;
      transition: opacity 0.3s ease;
    }
    
    .hero a:hover {
      opacity: 0.8;
    }
    
    /* Sections */
    section {
      padding: 60px 20px;
      max-width: 900px;
      margin: 0 auto;
    }
    
    h2 {
      margin-bottom: 30px;
      font-size: 2em;
      font-weight: 600;
      color: #2c3e50;
      border-bottom: 2px solid #e0e0e0;
      padding-bottom: 15px;
    }
    
    p {
      margin-bottom: 15px;
      line-height: 1.8;
      color: #555;
    }
    
    /* Schedule */
    .schedule ul {
      list-style-type: none;
    }
    
    .schedule li {
      margin-bottom: 20px;
      padding-left: 20px;
      position: relative;
    }
    
    .schedule li::before {
      content: '▸';
      position: absolute;
      left: 0;
      color: #2c3e50;
    }
    
    .schedule strong {
      color: #2c3e50;
      font-weight: 600;
    }
    
    /* Materials */
    .materials ul {
      list-style-type: none;
    }
    
    .materials li {
      margin-bottom: 15px;
    }
    
    .materials a {
      text-decoration: none;
      color: #3498db;
      font-weight: 500;
      transition: color 0.3s ease;
    }
    
    .materials a:hover {
      color: #2980b9;
      text-decoration: underline;
    }
    
    /* Speakers */
     .speaker-grid {
      display: flex;
      flex-direction: column;
      gap: 25px;
      margin-top: 30px;
    }
    
    .speaker {
      background-color: white;
      padding: 25px;
      border-radius: 12px;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
      transition: transform 0.3s ease, box-shadow 0.3s ease;
      display: flex;
      align-items: flex-start;
      gap: 25px;
    }
    
    .speaker:hover {
      transform: translateY(-3px);
      box-shadow: 0 8px 12px rgba(0, 0, 0, 0.15);
    }
    
    .speaker img {
      width: 120px;
      height: 120px;
      object-fit: cover;
      border-radius: 50%;
      border: 3px solid #f0f0f0;
      flex-shrink: 0;
    }
    
    .speaker-info {
      flex: 1;
    }
    
    .speaker-info h3 {
      margin: 0 0 10px 0;
      font-size: 20px;
      font-weight: 600;
    }
    
    .speaker-info h3 a {
      color: #2c3e50;
      text-decoration: none;
      transition: color 0.3s ease;
    }
    
    .speaker-info h3 a:hover {
      color: #3498db;
      text-decoration: underline;
    }
    
    .speaker-info p {
      margin: 0;
      font-size: 15px;
      line-height: 1.6;
      color: #555;
    }
    
    @media (max-width: 768px) {
      .header {
        padding: 10px 15px;
      }
      
      .navbar {
        gap: 0;
      }
      
      .navbar a {
        padding: 10px 16px;
        font-size: 13px;
      }
      
      .navbar a:not(:last-child)::after {
        display: none;
      }
      
      .hero h1 {
        font-size: 1.8em;
      }
      
      .hero p {
        font-size: 1em;
      }
      
      section {
        padding: 40px 15px;
      }
      
      .speaker {
        flex-direction: column;
        align-items: center;
        text-align: center;
      }
      
      .speaker img {
        margin-bottom: 15px;
      }
    }
  </style>
</head>
<body>
  <header class="header">
    <div class="logo">
      <a href="https://kdd2025.kdd.org/call-for-lecture-style-tutorials/">
        <img src="KDD25-Logo3.png" alt="KDD Logo">
      </a>
    </div>
    <nav class="navbar">
      <a href="#home">Home</a>
      <a href="#schedule">Schedule</a>
      <a href="#materials">Tutorial Materials</a>
      <a href="#contributors">Contributors</a>
    </nav>
  </header>

  <div class="hero" id="home">
    <div class="hero-content">
      <h1>Uncertainty Quantification and Confidence Calibration<br>in Large Language Models</h1>
      <p>2025 KDD Lecture-style Tutorial</p>
      <p>Sunday, August 3 &nbsp; 8:00 AM – 11:00 AM</p>
      <p>Location: <a href="https://www.mtccc.com/locations/" target="_blank">MTCC</a>, 255 Front Street West Toronto, Ontario, Canada</p>
    </div>
  </div>

  <section class="abstract">
    <h2>Abstract</h2>
    <p>
      Large Language Models (LLMs) excel in text generation, reasoning, and decision-making, enabling their adoption in high-stakes domains such as healthcare, law, and transportation. However, their reliability is a major concern, as they often produce plausible but incorrect responses. Uncertainty quantification (UQ) enhances trustworthiness by estimating confidence in outputs, enabling risk mitigation and selective prediction.
    </p>
    <p>
      However, traditional UQ methods struggle with LLMs due to computational constraints and decoding inconsistencies. Moreover, LLMs introduce unique uncertainty sources, such as input ambiguity, reasoning path divergence, and decoding stochasticity, that extend beyond classical aleatoric and epistemic uncertainty. To address this, we introduce a new taxonomy that categorizes UQ methods based on computational efficiency and uncertainty dimensions (input, reasoning, parameter, and prediction uncertainty). We evaluate existing techniques, assess their real-world applicability, and identify open challenges, emphasizing the need for scalable, interpretable, and robust UQ approaches to enhance LLM reliability.
    </p>
  </section>

  <section class="schedule" id="schedule">
    <h2>Schedule</h2>
    <ul>
      <li><strong>Section 1: Introduction and Overview (10 min)</strong><br>
        - LLMs and their growth<br>
        - Reliability concerns in sensitive applications<br>
        - Why we need Uncertainty Quantification and Confidence Calibration
      </li>
      <li><strong>Section 2: Define and understand LLM Uncertainty and Confidence (15 min)</strong><br>
        - Traditional UQ methods<br>
        - Aleatoric & Epistemic Uncertainty<br>
        - Limitations of traditional categories for LLMs<br>
        - Uncertainty vs. Confidence
      </li>
      <li><strong>Section 3: UQ Methods in LLMs (90 min)</strong><br>
        - Input uncertainty methods<br>
        - Reasoning uncertainty methods<br>
        - Parameter uncertainty methods<br>
        - Prediction uncertainty methods<br>
        <br><em>(Break - 10 min)</em><br>
      </li>
      <li><strong>Section 4: Confidence (20 min)</strong><br>
        - Confidence Estimation and Calibration<br>
        - Calibration methods in LLMs<br>
      </li>
      <li><strong>Section 5: Applications (15 min)</strong><br>
        - Robotics<br>
        - Transportation<br>
        - Healthcare<br>
        - Education
      </li>
      <li><strong>Section 6: Open Challenges and Future Directions (20 min)</strong><br>
        - Efficiency-Performance Trade-offs<br>
        - Interpretability Deficits<br>
        - Cross-Modality Uncertainty<br>
        - Interventions for Uncertainty<br>
        - UQ Evaluation
      </li>
      <li><strong>Q&A</strong></li>
    </ul>
  </section>

  <section class="materials" id="materials">
    <h2>Tutorial Materials</h2>
    <ul>
      <li><a href="https://drive.google.com/drive/folders/1duAqCy1_IR_Tpbd-NSv0dRik-LvZAeKT?usp=sharing" download>Download Slides</a></li>
      <li><a href="survey.pdf" download>Download Survey Paper (PDF)</a></li>
    </ul>
  </section>

  <section class="speakers" id="contributors">
    <h2>Contributors</h2>
    <div class="speaker-grid">
      <div class="speaker">
        <img src="people/xiaoou.png" alt="Xiaoou Liu">
        <div class="speaker-info">
          <h3><a href="https://xiao0o0o.github.io/" target="_blank">Xiaoou Liu</a></h3>
          <p>Xiaoou Liu is a second-year Ph.D. student in Computer Science at Arizona State University. Her research focuses on trustworthy machine learning, with an emphasis on explainable graph neural networks and uncertainty quantification in large language models. Her work has been published at venues such as KDD and ICCPS.</p>
        </div>
      </div>
      <div class="speaker">
        <img src="people/tiejin.png" alt="Tiejin Chen">
        <div class="speaker-info">
          <h3><a href="https://tiejin98.github.io/" target="_blank">Tiejin Chen</a></h3>
          <p>Tiejin Chen is a third-year Ph.D. student in Computer Science at Arizona State University. His research interests lie in trustworthy AI and its applications, with a focus on LLM reliability and safety. He has contributed to top conferences such as KDD, ACL, and AAAI, and is actively involved in research on LLM reliability and safety.  Tiejin has published in top venues including ACL, AAAI and SDM. He also actively contributes as a reviewer for major conferences in machine learning and data mining.</p>
        </div>
      </div>
      <div class="speaker">
        <img src="people/longchao.png" alt="Longchao Da">
        <div class="speaker-info">
          <h3><a href="https://longchaoda.github.io/LongchaoHere/" target="_blank">Longchao Da</a></h3>
          <p>Longchao is a fourth-year PhD candidate at Arizona State University. His research interests are RL and trustworthy AI. He has publications in top venues such as NeurIPS, ICML, KDD, AAAI, IJCAI, ECML-PKDD, CIKM, CDC, CASE, IJMLC, Machine Learning, and SDM. He successfully hosted in-person hands-on tutorials at the top inter-discipline venue, ITSC 2023 in Spain, with more than 60 participants.</p>
        </div>
      </div>
      <div class="speaker">
        <img src="people/zhenlin.jpg" alt="Zhen Lin">
        <div class="speaker-info">
          <h3><a href="https://zlin7.github.io/" target="_blank">Zhen Lin</a></h3>
          <p>Zhen finished his PhD study at the University of Illinois at Urbana-Champaign, and is a researcher at Jump Trading. His research interests are Uncertainty Quantification for Deep Learning and LLM. He has publications in top venues such as NeurIPS, ICLR, ICML, KDD, AAAI, and TMLR. He also co-hosted an in-person tutorial at KDD 2023.</p>
        </div>
      </div>
      <div class="speaker">
        <img src="people/chacha.jpg" alt="Chacha Chen">
        <div class="speaker-info">
          <h3><a href="https://chacha-chen.github.io/" target="_blank">Chacha Chen</a></h3>
          <p>Chacha Chen is a PhD candidate in Computer Science at the University of Chicago’s Human+AI Lab, advised by Chenhao Tan. Her research centers on understanding and adapting large language models for high-stakes, knowledge-intensive domains such as healthcare and on designing human-AI workflows that genuinely enhance expert decision-making. She has published papers at KDD, WWW, FAccT, ICLR, AAAI, ML4H and more, and has been recognized with the Best Applied Data Science Paper Award at ECML-PKDD 2020 and a Best Paper award at HMCaT @ ICML 2022.</p>
        </div>
      </div>
      <div class="speaker">
        <img src="people/hua.png" alt="Hua Wei">
        <div class="speaker-info">
          <h3><a href="https://labs.engineering.asu.edu/hw/" target="_blank">Hua Wei</a></h3>
          <p>Hua Wei is an Assistant Professor in the School of Computing and Augmented Intelligence at Arizona State University. His research focuses on data mining, reinforcement learning, and uncertainty quantification. He has been awarded the Amazon Research Award for LLM uncertainty quantification and multiple Best Paper Awards on top conferences in machine learning, artificial intelligence and data mining. He has also actively organized events related to uncertainty and LLMs, such as the Workshop on Uncertainty Reasoning and Quantification in Decision Making and Agent4IR workshops at CIKM and KDD.</p>
        </div>
      </div>
    </div>
  </section>
</body>
</html>